{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1HcpYuMYlPoEU_ogqzfgQN7XzConTQc4X",
      "authorship_tag": "ABX9TyPKe+l7RyIvhV2d180Pcy+v",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ragul-n/Gender-bias-in-Indian-cinema/blob/master/word2vec_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pysrt\n",
        "!pip install gensim\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DoqD9pYkYAMG",
        "outputId": "07fc8a34-bf3b-487e-d741-a99e176b1613"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pysrt\n",
            "  Downloading pysrt-1.1.2.tar.gz (104 kB)\n",
            "\u001b[K     |████████████████████████████████| 104 kB 31.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet in /usr/local/lib/python3.8/dist-packages (from pysrt) (3.0.4)\n",
            "Building wheels for collected packages: pysrt\n",
            "  Building wheel for pysrt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pysrt: filename=pysrt-1.1.2-py3-none-any.whl size=13443 sha256=472ceea6373b5ca5e042c58e418730b86cfbed5f48e6987950e340be846375e4\n",
            "  Stored in directory: /root/.cache/pip/wheels/30/a6/ab/4705174e11f44e74d58c14b32edbacbc852644f86658316aef\n",
            "Successfully built pysrt\n",
            "Installing collected packages: pysrt\n",
            "Successfully installed pysrt-1.1.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.8/dist-packages (3.6.0)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.8/dist-packages (from gensim) (1.21.6)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.8/dist-packages (from gensim) (1.7.3)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.8/dist-packages (from gensim) (1.15.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.8/dist-packages (from gensim) (6.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JFvha_VNNTA7",
        "outputId": "0e5c4026-adac-4f01-f5e5-0420735a30a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np \n",
        "import pysrt\n",
        "import os \n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "import gensim \n",
        "from gensim.parsing.preprocessing import preprocess_documents\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "class SentenceGenerator():\n",
        "    def __init__(self, dirname):\n",
        "        self.dirname = dirname\n",
        " \n",
        "    def __iter__(self):\n",
        "        for fname in os.listdir(self.dirname):\n",
        "\n",
        "            replace_dict={\n",
        "                \"\\n\":\". \",  \n",
        "                \"?.\":\"?\", \n",
        "                \"...\":\" \",\n",
        "                \",.\":\",\",\n",
        "                \"..\":\". \",\n",
        "                \"!.\":\"! \"\n",
        "            }\n",
        "\n",
        "            #.replace(\"\\n\",\".\").replace(\"?.\",\"? \")..replace(\"...\",\" \")\n",
        "\n",
        "            text=pysrt.open(os.path.join(self.dirname, fname)).text.lower()\n",
        "\n",
        "            for i in replace_dict.keys():\n",
        "                text=text.replace(i,replace_dict[i])\n",
        "\n",
        "            for sent in preprocess_documents(sent_tokenize(text)):\n",
        "                if len(sent)<5:\n",
        "                    continue\n",
        "                yield sent\n",
        "\n",
        "sentences=SentenceGenerator(\"/content/drive/MyDrive/Dataset/subtitles\")"
      ],
      "metadata": {
        "id": "pTuHcfHH6om6"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models.callbacks import CallbackAny2Vec\n",
        "\n",
        "\n",
        "\n",
        "class MonitorCallback(CallbackAny2Vec):\n",
        "    def on_epoch_end(self, model):\n",
        "        print(\"Model loss:\", model.get_latest_training_loss())  # print loss\n",
        "        model.save('/content/drive/MyDrive/Dataset/word2vec/subtitles')\n",
        "\n",
        "monitor = MonitorCallback()\n",
        "\n",
        "model = gensim.models.Word2Vec(sentences, size=300, window=6, min_count=10, workers=4, iter = 10, callbacks=[monitor])\n"
      ],
      "metadata": {
        "id": "B1DBmYM1Kho5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}